{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Spam Classification\n",
    "\n",
    "\n",
    "##  Details\n",
    "Spam refers to unwanted email, often in the form of advertisements. In the literature, an email that is **not** spam is called *ham*. Most email providers offer automatic spam filtering, where spam emails will be moved to a separate inbox based on their contents. Of course this requires being able to scan an email and determine whether it is spam or ham, a classification problem. \n",
    "\n",
    "You are welcome to use tools from libraries such as `numpy` and `scipy` to write your classifier.\n",
    "\n",
    "Note that while you may use tools such as the `cdist` function above, you **can not** import code which builds entire models. This includes but is not limited to use of a library like `scikit-learn`. \n",
    "\n",
    "The training data is described below and has 1000 rows. There is also a 500 row set of test data. These are functionally identical to the training data, they are just in a separate csv file to encourage you to split out your training and test data. You should consider how to best make use of all available data without overfitting and may wish to consider tools such as cross validation. This might be used, for example, to help decide what value of $k$ to use for k-nearest neighbour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One\n",
    "In this part you will write the code which builds the classifier. \n",
    "\n",
    "The cell below loads the training data into a variable called `training_spam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the spam training data set: (1000, 55)\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 1 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [1 1 1 ... 1 1 0]\n",
      " [1 0 0 ... 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "training_spam = np.loadtxt(open(\"data/training_spam.csv\"), delimiter=\",\").astype(np.int)\n",
    "print(\"Shape of the spam training data set:\", training_spam.shape)\n",
    "print(training_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your training set consists of 1000 rows and 55 columns. Each row corresponds to one email message. The first column is the _response_ variable and describes whether a message is spam `1` or ham `0`. The remaining 54 columns are _features_ that you will use to build a classifier. These features correspond to 54 different keywords (such as \"money\", \"free\", and \"receive\") and special characters (such as \":\", \"!\", and \"$\"). A feature has the value `1` if the keyword appears in the message and `0` otherwise.\n",
    "\n",
    "As mentioned there is also a 500 row set of *test data*. It contains the same 55 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your training set consists of 1000 rows and 55 columns. Each row corresponds to one email message. The first column is the _response_ variable and describes whether a message is spam `1` or ham `0`. The remaining 54 columns are _features_ that you will use to build a classifier. These features correspond to 54 different keywords (such as \"money\", \"free\", and \"receive\") and special characters (such as \":\", \"!\", and \"$\"). A feature has the value `1` if the keyword appears in the message and `0` otherwise.\n",
    "\n",
    "As mentioned there is also a 500 row set of *test data*. It contains the same 55 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the spam testing data set: (500, 55)\n",
      "[[1 0 0 ... 1 1 1]\n",
      " [1 1 0 ... 1 1 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "testing_spam = np.loadtxt(open(\"data/testing_spam.csv\"), delimiter=\",\").astype(np.int)\n",
    "print(\"Shape of the spam testing data set:\", testing_spam.shape)\n",
    "print(testing_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write all of the code for your classifier below this cell. There is some very rough skeleton code in the cell directly below. You may insert more cells below this if you wish.\n",
    "\n",
    "### Submission Requirements\n",
    "Your code must provide a variable with the name `classifier`. This object must have a method called `predict` which takes input data and returns class predictions. The input will be a single $n \\times 54$ numpy array, your classifier should return a numpy array of length $n$ with classifications. There is a demo in the cell below, and a test you can run before submitting to check your code is working correctly.\n",
    "\n",
    "Your code must run on our machines in under 60 seconds. If you wish to train a more complicated model (e.g. neural network) which will take longer, you are welcome to save the model's weights as a file and then load these in the cell below so we can test it. You must include the code which computes the original weights, but this must not run when we run the notebook – comment out the code which actually executes the routine and make sure it is clear what we need to change to get it to run. Remember that we will be testing your final classifier on additional hidden data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0: \t train_loss=0.30541 \t val_accuracy=0.916\n",
      "Epoch  1: \t train_loss=0.21283 \t val_accuracy=0.900\n",
      "Epoch  2: \t train_loss=0.19838 \t val_accuracy=0.928\n",
      "Epoch  3: \t train_loss=0.19072 \t val_accuracy=0.928\n",
      "Epoch  4: \t train_loss=0.19572 \t val_accuracy=0.920\n",
      "Epoch  5: \t train_loss=0.18905 \t val_accuracy=0.914\n",
      "Epoch  6: \t train_loss=0.18509 \t val_accuracy=0.912\n",
      "Epoch  7: \t train_loss=0.18582 \t val_accuracy=0.922\n",
      "Epoch  8: \t train_loss=0.17488 \t val_accuracy=0.918\n",
      "Epoch  9: \t train_loss=0.18229 \t val_accuracy=0.924\n",
      "Epoch 10: \t train_loss=0.18418 \t val_accuracy=0.930\n",
      "Epoch 11: \t train_loss=0.17460 \t val_accuracy=0.916\n",
      "Epoch 12: \t train_loss=0.17862 \t val_accuracy=0.914\n",
      "Epoch 13: \t train_loss=0.17576 \t val_accuracy=0.918\n",
      "Epoch 14: \t train_loss=0.17701 \t val_accuracy=0.924\n",
      "Epoch 15: \t train_loss=0.17841 \t val_accuracy=0.924\n",
      "Epoch 16: \t train_loss=0.17144 \t val_accuracy=0.928\n",
      "Epoch 17: \t train_loss=0.18010 \t val_accuracy=0.928\n",
      "Epoch 18: \t train_loss=0.17480 \t val_accuracy=0.918\n",
      "Epoch 19: \t train_loss=0.17216 \t val_accuracy=0.920\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.96      0.94       301\n",
      "         1.0       0.94      0.85      0.89       199\n",
      "\n",
      "    accuracy                           0.92       500\n",
      "   macro avg       0.92      0.91      0.92       500\n",
      "weighted avg       0.92      0.92      0.92       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This skeleton code simply classifies every input as ham\n",
    "#\n",
    "# Here you can see there is a parameter k that is unused, the\n",
    "# point is to show you how you could set up your own. You might\n",
    "# also pass in extra data via a train method (also does nothing\n",
    "# here). Modify this code as much as you like so long as the \n",
    "# accuracy test in the cell below runs.\n",
    "\n",
    "from bonz import BonzModel # import my model from my file bonz.py\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "NUM_LAYER = 4\n",
    "LAYER_DIMS = [256, 128, 64, 1]\n",
    "SCALE = 0.1\n",
    "LEARNING_RATE = 5e-3\n",
    "# Above hyperpameter can be chose by yourself\n",
    "\n",
    "classifier = BonzModel(num_layer=NUM_LAYER,\n",
    "                       layer_dims=LAYER_DIMS,\n",
    "                       scale=SCALE,\n",
    "                       lr=LEARNING_RATE,\n",
    "                       training_data=training_spam,\n",
    "                       testing_data=testing_spam\n",
    "                      )\n",
    "\n",
    "classifier.train(epoch=20, batch_size=16) # You can edit number of epochs and batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23709de2882e5c865ea3ad2b02de7fd4",
     "grade": true,
     "grade_id": "cell-b993518c6339eaf0",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data is: 0.918\n"
     ]
    }
   ],
   "source": [
    "# Write all of the code for your classifier above this cell.\n",
    "\n",
    "# This cell will run the test data through the classifier and print the accuracy. \n",
    "# The skeleton code above classifies every row as ham, but once you have written\n",
    "# your own classifier you can run this cell again to test it. So long as your code \n",
    "# sets up a variable called classifier with a method called predict, the test code \n",
    "# will be able to run. \n",
    "\n",
    "# You may want to create another verison of this cell for your own tests, especially\n",
    "# if you choose to split the training and test data differently from the default \n",
    "# 1000/500 split.\n",
    "\n",
    "# However you *must* ensure this version still runs before submitting.\n",
    "\n",
    "testing_spam = np.loadtxt(open(\"data/testing_spam.csv\"), delimiter=\",\").astype(np.int)\n",
    "test_data = testing_spam[:, 1:]\n",
    "test_labels = testing_spam[:, 0]\n",
    "\n",
    "predictions = classifier.predict(test_data)\n",
    "accuracy = np.count_nonzero(predictions == test_labels)/test_labels.shape[0]\n",
    "print(f\"Accuracy on test data is: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two\n",
    "In this part you will write a short discussion and analysis of your implementation in the cell below. \n",
    "\n",
    "* Please answer the following questions in your answer:\n",
    " * What supervised learning technique did you use?\n",
    " * How did you train it? How did you split training and test data? (If relevant.)\n",
    " * What accuracy percentage do you think your classifier will get on the *hidden* data?\n",
    "* You may also wish to discuss the following points:\n",
    " * Discuss the measured accuracy of your classifier in the context of the spam filtering problem.\n",
    " * For any parameters that were chosen by hand, explain your choices.\n",
    " * How could you further improve performance? (For any definition of performance.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "af728b7a0649d1b7c54040d56fe97f8a",
     "grade": true,
     "grade_id": "cell-208fb52194020411",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "## BONZ ANSWERS:\n",
    "### About my model:\n",
    "* I built neural network from scatch where I have to write the derivative of each layer (Linear and BCEwitSigmoid). \n",
    "* As there is a testing data with provided labels, the model was validated after every epoch. If no label is provided in the testing data, I will use 5-folds technique to valiate my model.\n",
    "* Since the training loss decreased significantly, I strongly believe the accuracy will be more than 0.9. But I think in the spam filter, precision score is important than other metrcs\n",
    "### OTHERS:\n",
    "* The most important in a spam filter system is precision score within spam emails. The reason for it is that we want to make sure any email that we marked as spam is actually a spam one.\n",
    "* All parameters are learnt within the neural network\n",
    "* Because I build this from scarch, there is no Dropout layer defined which can lead to over fitting. That means some parameters might dominate the rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Cell\n",
    "The cell below contains hidden tests for part one, please do not modify or delete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f59669b016ea021a93ff3c48c7bbf24",
     "grade": true,
     "grade_id": "cell-cfbacadfc7619537",
     "locked": true,
     "points": 80,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a test cell. Please do not modify or delete."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
